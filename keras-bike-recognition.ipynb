{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Welcome to assingment 3 of Machine Learning Course 5DV194! \n",
    "<span style=\"color:red\"> <em>Problem definition</em></span>: here in Umeå, you sometime heard about \"Someone stole my bike\", \"My bike is missing\" (see more [here](http://www.stulencykel.se/category/stad/umea/page/2/)). As a ML expert - (hopefully, after the assignment 2 :), you try to figure out how to solve the problem using a machine learning approach. Thinking thinking ....\n",
    "\n",
    "<span style=\"color:red\"> <em>Solution</em></span>: **\"Eureka\"**, it's a multi-class classification problem. Let's say we have a collection of all bike images and their owners in Umeå. When a random bike image is spotted on a bike market group, we can identify who is the owner of it. Sounds amazing? Let's get started. <br>\n",
    "\n",
    "There are two subtasks including (1) collect bike images and (2) build a multi-class classifier using a neural network on the collected dataset.\n",
    "\n",
    "#### Goals of assignment 3:\n",
    "Goal-1: Collect and explore a collection of bike images. <br> \n",
    "Goal-2: Build a convolutional neural network (CNN) for multi-class image classification (i.e., to identify whose bike is it).\n",
    "\n",
    "#### Deadline of assignment 3:\n",
    "March 23rd, 2018 (23:59:59 Stockholm time)\n",
    "\n",
    "#### Technologies to apply in assignment 3\n",
    "Machine Learning algorithm (i.e., Convolutional Neural Network)\n",
    "\n",
    "#### Dataset\n",
    "Work on a collected image dataset. The provided **dogs_cats_tiny** data is provided as a reference only (to make sure your model behaves properly on a working dataset). When your collected bike data is ready, you're supposed to work on the **bike data**, **NOT** the dogs_cats_tiny data. Note that collecting data is a 'boring' but also a very important step to work on a real-life problem. So please do it properly.\n",
    "\n",
    "#### Instruction\n",
    "Overall there are 3 tasks (steps) in this assingment.  To fulfill each task, you will find several TODO sections, which require you to add codes.  Anyway, just follow this file (ImageClassification_Student.ipynb) to run the GIVEN codes, and add your implemention (in TODO section) to accomplish all tasks. This time, you're **free to use any other libraries** as long as it helps your model improve the performance.\n",
    "\n",
    "#### Evaluation points distribution (100 points in total):\n",
    "Task 1. Collect 20 images of 5 different bikes. It means that you need to have 100 images in total. This is a very important part (data preparison/collection in machine learning) but may be 'boring'. That's why you can earn as much as **(60pt)**. <br>\n",
    "Task 2: Build a multi-class classification model using CNN **(34pt)**. <br>\n",
    "Task 3: Answer these questions **(6pt)**:\n",
    "- Question 1: how many samples do we have? (1pt) <br>\n",
    "- Question 2: how many classes do we have? (1pt) <br>\n",
    "- Question 3.1: How many layers are there in your model? (1pt)<br>\n",
    "- Question 3.2: What loss function did you use? (1pt)<br>\n",
    "- Question 3.3: What optimizer did you use? (1pt)<br>\n",
    "- Question 3.4: What evaluation metric did you use? (1pt)\n",
    "\n",
    "<br>**Note**: All of your answers, codes, and trained models are validated <span style=\"color:red\"> <em>automatically</em></span>. So please make sure you are following all instructions properly. We will have a closer look into your problem but your grade will not be changed since it depends on your submitted codes/files. <br>\n",
    "<span style=\"color:red\"> <em>INFORMATION:</em></span> You're not allowed to publish this code to any other third-party."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preparation. \n",
    "To make sure (1) your python environment is well prepared and (2) output files are well-organised, we have this initial section to make them right.\n",
    "1. Read instruction from **build_env.note** to install all required packages\n",
    "2. Run the following code block to make sure you're ready to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named numpy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-842363fcb733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import some basic libraries. Again, feel free to add new libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named numpy"
     ]
    }
   ],
   "source": [
    "# Import some basic libraries. Again, feel free to add new libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, Conv2D\n",
    "from keras import optimizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /import/software/anaconda/5.1-py2/envs/ipykernel_py2_ml/lib/python2.7/site-packages\n",
      "Requirement already satisfied: numpy>=1.9.1 in /import/software/anaconda/5.1-py2/envs/ipykernel_py2_ml/lib/python2.7/site-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /import/software/anaconda/5.1-py2/envs/ipykernel_py2_ml/lib/python2.7/site-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /import/software/anaconda/5.1-py2/envs/ipykernel_py2_ml/lib/python2.7/site-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /import/software/anaconda/5.1-py2/envs/ipykernel_py2_ml/lib/python2.7/site-packages (from keras)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "/pkg/anaconda/5.1-py2/envs/ipykernel_py2_ml/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Now, we install some requirements for this assignment (it's keras, tensorflow). \n",
    "!pip install keras\n",
    "!KERAS_BACKEND=tensorflow python -c \"from keras import backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's define some required variables for storing outputs.\n",
    "from random import randint\n",
    "random_id = randint(3,7000)\n",
    "answers_out = {}\n",
    "answers_out['#rand_id=']='{}'.format(random_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Building an image classification model using very little data  \n",
    "\n",
    "In this part, you have to build an image classifier using keras from just a few sample pictures from the provided **cats_dogs_tiny** data.\n",
    "\n",
    "We will go over the following tasks:\n",
    "\n",
    "- training a baseline CNN neural network\n",
    "- applying the model to your collected bike images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Data structure under **data/student_collected_data** folder should look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "data/student_collected_data/\n",
    "    train/\n",
    "        bike1/ ### n1 pictures\n",
    "            *.jpg\n",
    "            *.jpg\n",
    "            ...\n",
    "        bike5/ ### n2 pictures\n",
    "            *.jpg\n",
    "            *.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        bike1/ ### n3 pictures\n",
    "            *.jpg\n",
    "            *.jpg\n",
    "            ...\n",
    "        bike5/ ### n4 pictures\n",
    "            *.jpg\n",
    "            *.jpg\n",
    "            ...\n",
    "```\n",
    "Note: \n",
    "- After collecting all images of each bike, you divide 20% to validation, 80% to train. \n",
    "- We're going to walk you through **dogs_cats_tiny** data. However, every process of **student_collected_data** is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO (task 1): \n",
    "Using your mobile phone (or camera) to collect your own bike images (5 bikes, each bike has 20 images). Try to take different angles of a bike. See some pics [here](http://www.wiggle.com/vitus-bikes-nucleus-275-vrs-hardtail-bike-rockshox/) to know how people take pictures of bikes. Do not get images from the internet because we want you to experience the real use-case of collecting data. And after all, you will get a bunch of scores for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  validation\r\n"
     ]
    }
   ],
   "source": [
    "# Let's set dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# TODO: replace these 2 parts with your bike data\n",
    "train_data_dir = 'data/student_collected_data/train'\n",
    "validation_data_dir = 'data/student_collected_data/validation'\n",
    "!ls ./data/student_collected_data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Question 1: how many samples do we have?\n",
    "answers_out['#sample'] = 100 # TODO: replace -1 by your answer above\n",
    "# Question 2: how many classes do we have?\n",
    "answers_out['#classes'] = 5 # TODO: replace -1 by your answer above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 5 classes.\n",
      "Found 20 images belonging to 5 classes.\n",
      "('#ofFileSamples:', 80)\n",
      "('Class Indices: ', {'bike1': 0, 'bike2': 1, 'bike3': 2, 'bike4': 3, 'bike5': 4})\n",
      "('#ofClass:', 5)\n"
     ]
    }
   ],
   "source": [
    "# Don't modify this part. We're going to generate features for our images\n",
    "# Step1: we rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "data_gen = ImageDataGenerator(rescale=1./255)\n",
    "train_batch_size = 16\n",
    "val_batch_size = 32\n",
    "# Step2: create train generator and validation generator\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "# class_mode: \n",
    "# Default: \"categorical\". Determines the type of label arrays that are returned: \n",
    "# \"categorical\" will be 2D one-hot encoded labels, \"binary\" will be 1D binary labels, \n",
    "# \"sparse\" will be 1D integer labels, \n",
    "# \"input\" will be images identical to input images (mainly used to work with autoencoders)\n",
    "\n",
    "# Transform the images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=train_batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=val_batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "print(\"#ofFileSamples:\", len(train_generator.filenames))\n",
    "print(\"Class Indices: \", train_generator.class_indices)\n",
    "print(\"#ofClass:\", len(train_generator.class_indices))\n",
    "\n",
    "# convert the training labels to categorical vectors\n",
    "# get the class lebels for the training data, in the original order\n",
    "train_labels = train_generator.classes\n",
    "num_classes = len(train_generator.class_indices)\n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A baseline Conv Net model\n",
    "### Model architecture definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# TODO: go to `image_classifiers.py` and implement your basic_cnn_model and run it here.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from image_classifiers import basic_cnn_model\n",
    "model = basic_cnn_model(img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 146, 146, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 69, 69, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 34, 34, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 30, 30, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 11, 11, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 284,581\n",
      "Trainable params: 284,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Drawing model summary. \n",
    "# Write the model summary out\n",
    "with open('trained_models/cnn_model_summary.txt','w') as model_sum_writer:\n",
    "    model.summary(print_fn=lambda x: model_sum_writer.write(x + '\\n'))\n",
    "    \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's go for training\n",
    "nb_epoch = 5\n",
    "nb_train_samples = len(train_generator.filenames)\n",
    "nb_validation_samples = len(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 1.6105 - acc: 0.2078 - val_loss: 1.5797 - val_acc: 0.2500\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 35s 443ms/step - loss: 1.3994 - acc: 0.3766 - val_loss: 1.2313 - val_acc: 0.6000\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 35s 441ms/step - loss: 0.7862 - acc: 0.6672 - val_loss: 1.4014 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 35s 441ms/step - loss: 0.4034 - acc: 0.8539 - val_loss: 1.0025 - val_acc: 0.8000\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 35s 438ms/step - loss: 0.2123 - acc: 0.9273 - val_loss: 1.1058 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# Only train when model isn't loaded.\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=nb_epoch,\n",
    "        steps_per_epoch=nb_train_samples,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples)\n",
    "# Don't modify this part.\n",
    "model.save_weights('trained_models/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing loss and accuracy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1057684659957885, 0.8500000238418579)\n"
     ]
    }
   ],
   "source": [
    "# Don't modify this part.\n",
    "eval_loss, eval_acc = model.evaluate_generator(validation_generator, nb_validation_samples)\n",
    "answers_out['eval_loss'] = eval_loss\n",
    "answers_out['eval_acc'] = eval_acc\n",
    "print (eval_loss, eval_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After ~5 epochs the neural network reach ~62% accuracy. Now, do all the process again with your collected data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 3.1: How many layers are there in your model?\n",
    "answers_out['classifier_n_layers'] = len(model.layers) # replace '-1' with your answer\n",
    "# Question 3.2: What loss function did you use?\n",
    "answers_out['classifier_loss_func'] = \"categorical_crossentropy\" # replace NULL with your answer\n",
    "# Question 3.3: What optimizer did you use?\n",
    "answers_out['classifier_optimizer'] = \"adam\" # replace NULL with your answer\n",
    "# Question 3.4: What evaluation metric did you use?\n",
    "answers_out['classifier_eval_metric'] = \"accuracy\" # replace NULL with your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't modify this part. \n",
    "# Write output to a file.\n",
    "from py_utils import write_answers, reload_answers\n",
    "write_answers(answers_out, \"trained_models/answer_outputs.txt\")\n",
    "\n",
    "# Make sure we can read and reload from your output file\n",
    "dict_outputs = reload_answers(\"trained_models/answer_outputs.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations. You're done with the assignment 3. \n",
    "\n",
    "You need to submit a <span style=\"color:red\"> <em>your_name_ml2018_assignment3.zip</span> file. Remember to replace *your_name* part with your firstname_givenname. \n",
    "\n",
    "We will evaluate both of your output files and your implementations through a number of tests.\n",
    "Structure of your compressed file after extraction:\n",
    "```\n",
    "./<your_name>_ml2018_assignment3\n",
    "├── data/                     // contains your collected data.\n",
    "│   ├── student_collected_data\n",
    "│       ├── train             // contains your trained data\n",
    "│       ├── validation        // contains your validation data\n",
    "│\n",
    "├── image_classifiers.py      // contains your neural network model.\n",
    "├── trained_models            // all auto-generated files\n",
    "│   ├── cnn_model.h5\n",
    "│   ├── answer_outputs.txt    // your answers from this Jupyter Notebook file.\n",
    "│   ├── cnn_model_summary.txt // summary of your RNN model.\n",
    "└── ImageClassification_Student.ipynb  // this file with all of your outputs\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
